{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a3cddaccf9a8427aa5aba5cc6ed65955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e3c93223d4c485a8751dd1a82a033b3",
              "IPY_MODEL_eb395aa4b5d1494794c45c467ee9d163",
              "IPY_MODEL_7c1d07369a18446087bb730a36d7f3a7"
            ],
            "layout": "IPY_MODEL_4325b12629b94dcbbc23a147a9dbd1af"
          }
        },
        "7e3c93223d4c485a8751dd1a82a033b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76480b6c9581499093e95fa4dee918c2",
            "placeholder": "​",
            "style": "IPY_MODEL_2fce164ac1894cd6a58c08c050205e12",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "eb395aa4b5d1494794c45c467ee9d163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f658f18b303f4fa09b176fb9d2880b16",
            "max": 1951,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e37d495cb474d1290e63fcaa8affb86",
            "value": 1951
          }
        },
        "7c1d07369a18446087bb730a36d7f3a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a298c3732594cd3ac580ddf7e44c467",
            "placeholder": "​",
            "style": "IPY_MODEL_531ed36c1cab45e4b8ba2c6afcb7cbed",
            "value": " 1.95k/1.95k [00:00&lt;00:00, 232kB/s]"
          }
        },
        "4325b12629b94dcbbc23a147a9dbd1af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76480b6c9581499093e95fa4dee918c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fce164ac1894cd6a58c08c050205e12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f658f18b303f4fa09b176fb9d2880b16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e37d495cb474d1290e63fcaa8affb86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a298c3732594cd3ac580ddf7e44c467": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "531ed36c1cab45e4b8ba2c6afcb7cbed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd5d62b8166842ae9d5b36124a5ea842": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81982c3a60894a53ada74db853f03ce4",
              "IPY_MODEL_1bc234a85b6a4fd69b0c1ff542bcb3ce",
              "IPY_MODEL_e635e1124a9c4db49520e1f090f2f02a"
            ],
            "layout": "IPY_MODEL_8c7ed90a89cd4f959d6fcadcdb254d15"
          }
        },
        "81982c3a60894a53ada74db853f03ce4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_094057d9d24b48b3bf1ff796b52c0feb",
            "placeholder": "​",
            "style": "IPY_MODEL_896c14e5bbbc4a5eaa1fe68720d4a0e2",
            "value": "spiece.model: 100%"
          }
        },
        "1bc234a85b6a4fd69b0c1ff542bcb3ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0b79f5456e34ecc930f56348cc9e956",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b756e2e72c74ad593272b3dbce0e9d0",
            "value": 791656
          }
        },
        "e635e1124a9c4db49520e1f090f2f02a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed955a374f224c91bd4fc435bb58eefb",
            "placeholder": "​",
            "style": "IPY_MODEL_37ea5ffc92b5406fb1d337b1a0a1f79c",
            "value": " 792k/792k [00:00&lt;00:00, 24.4MB/s]"
          }
        },
        "8c7ed90a89cd4f959d6fcadcdb254d15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "094057d9d24b48b3bf1ff796b52c0feb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "896c14e5bbbc4a5eaa1fe68720d4a0e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0b79f5456e34ecc930f56348cc9e956": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b756e2e72c74ad593272b3dbce0e9d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed955a374f224c91bd4fc435bb58eefb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37ea5ffc92b5406fb1d337b1a0a1f79c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1af83668d27c45dab8926dda62a974c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d69249661521429e9bfafb4dc3b09c80",
              "IPY_MODEL_7f86a0b0ce944c928b7192e2a406e4e6",
              "IPY_MODEL_1c6ef71610384a518e7326564b7622af"
            ],
            "layout": "IPY_MODEL_81bf1cdc012e4a6b82dd1fb33bbc11dd"
          }
        },
        "d69249661521429e9bfafb4dc3b09c80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d095f64c508e42bab7b39a469966952f",
            "placeholder": "​",
            "style": "IPY_MODEL_29cc3177e0674ae8b5cd34f5f51a50b9",
            "value": "tokenizer.json: 100%"
          }
        },
        "7f86a0b0ce944c928b7192e2a406e4e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a95e3268b5984d1a826f42d3e5c3628f",
            "max": 2424064,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a0626953289432aaf371f16287b4197",
            "value": 2424064
          }
        },
        "1c6ef71610384a518e7326564b7622af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c277cd8e0974286bc7255bb280b6c09",
            "placeholder": "​",
            "style": "IPY_MODEL_3a29f75050f34121878a98eb09693ff4",
            "value": " 2.42M/2.42M [00:00&lt;00:00, 3.77MB/s]"
          }
        },
        "81bf1cdc012e4a6b82dd1fb33bbc11dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d095f64c508e42bab7b39a469966952f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29cc3177e0674ae8b5cd34f5f51a50b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a95e3268b5984d1a826f42d3e5c3628f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a0626953289432aaf371f16287b4197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c277cd8e0974286bc7255bb280b6c09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a29f75050f34121878a98eb09693ff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffbee9140b1a46fe83ba1ecabb8bbb0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d07c8872fa5442f92b1c46bd2363dc4",
              "IPY_MODEL_6b960c7436cd44d592417dcddf26b0e5",
              "IPY_MODEL_06c327cde6f542a1b3d7f60f215b0b79"
            ],
            "layout": "IPY_MODEL_b92eac0d43844dac9fa733be4db19167"
          }
        },
        "9d07c8872fa5442f92b1c46bd2363dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ad5b882b079472da66cdd5f6df6ab02",
            "placeholder": "​",
            "style": "IPY_MODEL_fb7786d2f4644dc88ff9f75ffb948c66",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "6b960c7436cd44d592417dcddf26b0e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6870b449bfad42358ae3767a1ee495e4",
            "max": 1786,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d53d544ae18e4983a218aed598e29202",
            "value": 1786
          }
        },
        "06c327cde6f542a1b3d7f60f215b0b79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcb1b6d1bc994df88c7f7765a45f7b9b",
            "placeholder": "​",
            "style": "IPY_MODEL_fe0d77227ee740439bab592c27ed63a0",
            "value": " 1.79k/1.79k [00:00&lt;00:00, 221kB/s]"
          }
        },
        "b92eac0d43844dac9fa733be4db19167": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ad5b882b079472da66cdd5f6df6ab02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb7786d2f4644dc88ff9f75ffb948c66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6870b449bfad42358ae3767a1ee495e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d53d544ae18e4983a218aed598e29202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dcb1b6d1bc994df88c7f7765a45f7b9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe0d77227ee740439bab592c27ed63a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0793ce31ff1941228375d3c2a37f4cb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ffe11019a2ce4b13a87b9145c067492e",
              "IPY_MODEL_5d97a3b7c0574b588dc4d3879b7895db",
              "IPY_MODEL_90dad65e28cc456bb5eec0aaeb5c59c7"
            ],
            "layout": "IPY_MODEL_55e6476933964a55ad712aaace556e42"
          }
        },
        "ffe11019a2ce4b13a87b9145c067492e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91cb53d1540f43d882b2da3e928278f6",
            "placeholder": "​",
            "style": "IPY_MODEL_d5c2dc5466b84fceb99cba5b502bbff7",
            "value": "config.json: 100%"
          }
        },
        "5d97a3b7c0574b588dc4d3879b7895db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1f0e976b9db455c88bdcff84154f8fe",
            "max": 729,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a953a42d61a4974998b99e60b8f54fb",
            "value": 729
          }
        },
        "90dad65e28cc456bb5eec0aaeb5c59c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b181ab18740f46fcaabaaa81f2ab7c70",
            "placeholder": "​",
            "style": "IPY_MODEL_5c2877d29e57405ca1af72fb7d785742",
            "value": " 729/729 [00:00&lt;00:00, 71.2kB/s]"
          }
        },
        "55e6476933964a55ad712aaace556e42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91cb53d1540f43d882b2da3e928278f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5c2dc5466b84fceb99cba5b502bbff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1f0e976b9db455c88bdcff84154f8fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a953a42d61a4974998b99e60b8f54fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b181ab18740f46fcaabaaa81f2ab7c70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c2877d29e57405ca1af72fb7d785742": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4d937ee020a42938efc95bb41773ad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b81c32e14754e31afe4a34bef4349f9",
              "IPY_MODEL_4cd6b20acc6f4ab48a2bfedf1294f9bf",
              "IPY_MODEL_a3daac22b6cc4f059763736731cb5829"
            ],
            "layout": "IPY_MODEL_4c7c208e8ac54331835f511f2a49d28f"
          }
        },
        "6b81c32e14754e31afe4a34bef4349f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_385053ea834d42039ff2bf7a53a62afb",
            "placeholder": "​",
            "style": "IPY_MODEL_6bcfa407ca0d43799ff9460b6a691351",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "4cd6b20acc6f4ab48a2bfedf1294f9bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63fa2fafddc1490d8fed3dbc7732c2f7",
            "max": 891697151,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35a5e49a9bef4422bd999d9c26271793",
            "value": 891697151
          }
        },
        "a3daac22b6cc4f059763736731cb5829": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebd636ee8abd43fb9874f8b98df39ba0",
            "placeholder": "​",
            "style": "IPY_MODEL_804eea4587d245488750630da87af666",
            "value": " 892M/892M [00:02&lt;00:00, 405MB/s]"
          }
        },
        "4c7c208e8ac54331835f511f2a49d28f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "385053ea834d42039ff2bf7a53a62afb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bcfa407ca0d43799ff9460b6a691351": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63fa2fafddc1490d8fed3dbc7732c2f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35a5e49a9bef4422bd999d9c26271793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ebd636ee8abd43fb9874f8b98df39ba0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "804eea4587d245488750630da87af666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers optimum onnx onnxruntime\n",
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "BB5FvaRV4Kxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "!pip uninstall torch torchvision -y\n",
        "!pip install torch torchvision\n",
        "!pip install datasets\n",
        "!pip install --upgrade transformers\n",
        "import json\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from google.colab import drive\n",
        "import evaluate\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torchvision\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import AutoConfig\n",
        "from transformers import LogitsProcessorList, MinLengthLogitsProcessor\n",
        "from uuid import uuid4\n",
        "from optimum.exporters.onnx import main_export\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "o2IIyrdR4XGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/BUE_ICS_AI_Dataset_NLP QG.json', 'r') as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "# Creating a new list to store the modified dataset\n",
        "modified_dataset = []\n",
        "\n",
        "# Looping through each item in the original dataset and modify the structure\n",
        "for item in dataset:\n",
        "\n",
        "    context = item.get(\"input\")  # 'input' is the passage\n",
        "    question = item.get(\"output\")  # 'output' is the question\n",
        "    instruction = item.get(\"instruction\")  # 'instruction' remains as is\n",
        "\n",
        "    modified_item = {\n",
        "        \"context\": context,\n",
        "        \"question\": question,\n",
        "        \"instruction\": instruction\n",
        "    }\n",
        "\n",
        "    modified_dataset.append(modified_item)\n",
        "\n",
        "with open('modified_dataset.json', 'w') as f:\n",
        "    json.dump(modified_dataset, f, indent=4)\n",
        "\n",
        "print(\"Dataset has been successfully modified and saved to 'modified_dataset.json'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qYUW3PO1-Fv",
        "outputId": "aa8ad948-61a6-45b2-9a3e-6aa31c67102b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset has been successfully modified and saved to 'modified_dataset.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading the modified dataset**"
      ],
      "metadata": {
        "id": "dhH3COdnecmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('modified_dataset.json', 'r') as f:\n",
        "    modified_dataset = json.load(f)\n",
        "\n",
        "for i, item in enumerate(modified_dataset[:5]):\n",
        "    print(f\"Entry {i+1}:\")\n",
        "    print(f\"Context: {item.get('context')}\")\n",
        "    print(f\"Question: {item.get('question')}\")\n",
        "    print(f\"Instruction: {item.get('instruction')}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "print(f\"Total number of entries in the modified dataset: {len(modified_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EQg68yz2PE8",
        "outputId": "1ac4e54b-2962-4edc-be4a-dcef94bbf430"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entry 1:\n",
            "Context: NLP stands for Natural Language Processing, which involves enabling computers to understand and generate human language.\n",
            "Question: What does NLP stand for in the field of Artificial Intelligence?\n",
            "A. Natural Logic Processing\n",
            "B. Natural Language Processing\n",
            "C. Neural Linguistic Programming\n",
            "D. Natural Level Programming\n",
            "Instruction: Generate a multiple-choice question based on the following passage.\n",
            "----------------------------------------\n",
            "Entry 2:\n",
            "Context: One of the core goals of NLP is to allow machines to understand, interpret, and generate human language.\n",
            "Question: True or False: NLP allows machines to interact using human language.\n",
            "Instruction: Generate a true or false question based on the following passage.\n",
            "----------------------------------------\n",
            "Entry 3:\n",
            "Context: Text lacks components like visual perception, emotion, and interaction with the physical world, which are vital for full intelligence.\n",
            "Question: Why was text previously considered a limited source of information for AI systems?\n",
            "A. Text is always biased.\n",
            "B. AI lacked the ability to read.\n",
            "C. Text alone couldn't represent full human intelligence like perception or physical interaction.\n",
            "D. Text data is structured and simple.\n",
            "Instruction: Generate a multiple-choice question based on the following passage.\n",
            "----------------------------------------\n",
            "Entry 4:\n",
            "Context: generate\n",
            "Question: Fill in the blank: Natural Language Processing helps computers to understand and ______ human language.\n",
            "Instruction: Generate a fill-in-the-blank question based on the following passage.\n",
            "----------------------------------------\n",
            "Entry 5:\n",
            "Context: Early systems mainly struggled with ambiguity, emotional content, and context — not computational power.\n",
            "Question: Which of the following is NOT a challenge faced by early AI systems in dealing with human language?\n",
            "A. Ambiguity in language\n",
            "B. Lack of structured data\n",
            "C. Emotional understanding\n",
            "D. High computational power\n",
            "Instruction: Generate a multiple-choice question based on the following passage.\n",
            "----------------------------------------\n",
            "Total number of entries in the modified dataset: 5158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocessing: Split the Dataset**"
      ],
      "metadata": {
        "id": "Go2Dyzi53Kcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('modified_dataset.json', 'r') as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "# Split the dataset into training (80%), evaluation and test (20%) datasets\n",
        "train_data, temp_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "eval_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
        "\n",
        "with open('train_data.json', 'w') as f:\n",
        "    json.dump(train_data, f, indent=4)\n",
        "\n",
        "with open('eval_data.json', 'w') as f:\n",
        "    json.dump(eval_data, f, indent=4)\n",
        "\n",
        "with open('test_data.json', 'w') as f:\n",
        "    json.dump(test_data, f, indent=4)\n",
        "\n",
        "print(\"Dataset split successfully into train, evaluation, and test sets.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-stEm0Y3LNM",
        "outputId": "50d7e965-2d24-4469-cd23-8e65502c9893"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split successfully into train, evaluation, and test sets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load the Model and Tokenizer**"
      ],
      "metadata": {
        "id": "kpwTNcXI3Oq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('frozenwalker/SciFive_pubmedqa_question_generation')\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained('frozenwalker/SciFive_pubmedqa_question_generation')\n",
        "\n",
        "print(\"Model and tokenizer loaded successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226,
          "referenced_widgets": [
            "a3cddaccf9a8427aa5aba5cc6ed65955",
            "7e3c93223d4c485a8751dd1a82a033b3",
            "eb395aa4b5d1494794c45c467ee9d163",
            "7c1d07369a18446087bb730a36d7f3a7",
            "4325b12629b94dcbbc23a147a9dbd1af",
            "76480b6c9581499093e95fa4dee918c2",
            "2fce164ac1894cd6a58c08c050205e12",
            "f658f18b303f4fa09b176fb9d2880b16",
            "8e37d495cb474d1290e63fcaa8affb86",
            "1a298c3732594cd3ac580ddf7e44c467",
            "531ed36c1cab45e4b8ba2c6afcb7cbed",
            "dd5d62b8166842ae9d5b36124a5ea842",
            "81982c3a60894a53ada74db853f03ce4",
            "1bc234a85b6a4fd69b0c1ff542bcb3ce",
            "e635e1124a9c4db49520e1f090f2f02a",
            "8c7ed90a89cd4f959d6fcadcdb254d15",
            "094057d9d24b48b3bf1ff796b52c0feb",
            "896c14e5bbbc4a5eaa1fe68720d4a0e2",
            "d0b79f5456e34ecc930f56348cc9e956",
            "5b756e2e72c74ad593272b3dbce0e9d0",
            "ed955a374f224c91bd4fc435bb58eefb",
            "37ea5ffc92b5406fb1d337b1a0a1f79c",
            "1af83668d27c45dab8926dda62a974c7",
            "d69249661521429e9bfafb4dc3b09c80",
            "7f86a0b0ce944c928b7192e2a406e4e6",
            "1c6ef71610384a518e7326564b7622af",
            "81bf1cdc012e4a6b82dd1fb33bbc11dd",
            "d095f64c508e42bab7b39a469966952f",
            "29cc3177e0674ae8b5cd34f5f51a50b9",
            "a95e3268b5984d1a826f42d3e5c3628f",
            "2a0626953289432aaf371f16287b4197",
            "8c277cd8e0974286bc7255bb280b6c09",
            "3a29f75050f34121878a98eb09693ff4",
            "ffbee9140b1a46fe83ba1ecabb8bbb0d",
            "9d07c8872fa5442f92b1c46bd2363dc4",
            "6b960c7436cd44d592417dcddf26b0e5",
            "06c327cde6f542a1b3d7f60f215b0b79",
            "b92eac0d43844dac9fa733be4db19167",
            "8ad5b882b079472da66cdd5f6df6ab02",
            "fb7786d2f4644dc88ff9f75ffb948c66",
            "6870b449bfad42358ae3767a1ee495e4",
            "d53d544ae18e4983a218aed598e29202",
            "dcb1b6d1bc994df88c7f7765a45f7b9b",
            "fe0d77227ee740439bab592c27ed63a0",
            "0793ce31ff1941228375d3c2a37f4cb0",
            "ffe11019a2ce4b13a87b9145c067492e",
            "5d97a3b7c0574b588dc4d3879b7895db",
            "90dad65e28cc456bb5eec0aaeb5c59c7",
            "55e6476933964a55ad712aaace556e42",
            "91cb53d1540f43d882b2da3e928278f6",
            "d5c2dc5466b84fceb99cba5b502bbff7",
            "f1f0e976b9db455c88bdcff84154f8fe",
            "6a953a42d61a4974998b99e60b8f54fb",
            "b181ab18740f46fcaabaaa81f2ab7c70",
            "5c2877d29e57405ca1af72fb7d785742",
            "a4d937ee020a42938efc95bb41773ad3",
            "6b81c32e14754e31afe4a34bef4349f9",
            "4cd6b20acc6f4ab48a2bfedf1294f9bf",
            "a3daac22b6cc4f059763736731cb5829",
            "4c7c208e8ac54331835f511f2a49d28f",
            "385053ea834d42039ff2bf7a53a62afb",
            "6bcfa407ca0d43799ff9460b6a691351",
            "63fa2fafddc1490d8fed3dbc7732c2f7",
            "35a5e49a9bef4422bd999d9c26271793",
            "ebd636ee8abd43fb9874f8b98df39ba0",
            "804eea4587d245488750630da87af666"
          ]
        },
        "id": "VyPAuqDe3QXr",
        "outputId": "1df1bf28-28ff-483d-8349-9674751342bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.95k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3cddaccf9a8427aa5aba5cc6ed65955"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd5d62b8166842ae9d5b36124a5ea842"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1af83668d27c45dab8926dda62a974c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ffbee9140b1a46fe83ba1ecabb8bbb0d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/729 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0793ce31ff1941228375d3c2a37f4cb0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4d937ee020a42938efc95bb41773ad3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = AutoConfig.from_pretrained(\"frozenwalker/SciFive_pubmedqa_question_generation\")\n",
        "\n",
        "# Check the model size\n",
        "print(f\"Model architecture: {config.architectures}\")\n",
        "print(f\"Model size: {config.model_type}\")\n",
        "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "66JVMFIjQuXn",
        "outputId": "12b289c3-13cb-4e44-98e3-bad240ebfdbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model architecture: ['T5ForConditionalGeneration']\n",
            "Model size: t5\n",
            "Number of parameters: 222903552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocessing for Fine-Tuning**"
      ],
      "metadata": {
        "id": "I_hwaGzb3R8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QuestionGenerationDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length=512): # max_length=512 was chosen based on the model's original configuration and the average context length in my dataset.\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        context = item[\"context\"]\n",
        "        question = item[\"question\"]\n",
        "\n",
        "        # Tokenizing the input and output\n",
        "        inputs = self.tokenizer(context, padding='max_length', truncation=True, max_length=self.max_length, return_tensors=\"pt\")\n",
        "        labels = self.tokenizer(question, padding='max_length', truncation=True, max_length=self.max_length, return_tensors=\"pt\")\n",
        "\n",
        "        # Preparing the data for training\n",
        "        input_ids = inputs['input_ids'].squeeze()\n",
        "        attention_mask = inputs['attention_mask'].squeeze()\n",
        "        labels = labels['input_ids'].squeeze()\n",
        "\n",
        "        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels}\n",
        "\n",
        "# Creating dataset objects for training and evaluation\n",
        "train_dataset = QuestionGenerationDataset(train_data, tokenizer)\n",
        "eval_dataset = QuestionGenerationDataset(eval_data, tokenizer)\n",
        "\n",
        "print(\"Datasets created successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_m8Zjlv3T-Y",
        "outputId": "b446ec8b-d199-4423-8818-727e1a8e2528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fine-Tuning the Model**"
      ],
      "metadata": {
        "id": "3335C8MH3ZSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('frozenwalker/SciFive_pubmedqa_question_generation')\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained('frozenwalker/SciFive_pubmedqa_question_generation')\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    logits, labels = pred\n",
        "    preds = torch.argmax(torch.tensor(logits), dim=-1)\n",
        "    return accuracy.compute(predictions=preds, references=labels)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    eval_steps=500,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    weight_decay=0.01,\n",
        "    num_train_epochs=12,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=200,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.save_model('./fine_tuned_model')\n",
        "print(\"Model fine-tuning complete and saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6dYAxbI93aKg",
        "outputId": "22d4b1ee-398f-49c2-b0b9-08e3fe79fc99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmostaphaabdulaziz132\u001b[0m (\u001b[33mmostaphaabdulaziz132-bue\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250422_051034-w91lr7sh</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mostaphaabdulaziz132-bue/huggingface/runs/w91lr7sh' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/mostaphaabdulaziz132-bue/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mostaphaabdulaziz132-bue/huggingface' target=\"_blank\">https://wandb.ai/mostaphaabdulaziz132-bue/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mostaphaabdulaziz132-bue/huggingface/runs/w91lr7sh' target=\"_blank\">https://wandb.ai/mostaphaabdulaziz132-bue/huggingface/runs/w91lr7sh</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6192' max='6192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6192/6192 55:16, Epoch 12/12]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>3.214800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.132300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.106800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.094600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.090600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.086000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.078800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.080200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.076700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.073500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.072500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.069500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.069500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.070100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.068200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.065000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.064200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.064900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.064200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.063000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.063600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.060400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.061700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.060200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.061200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.061100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.059400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.061000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.059200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.059900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model fine-tuning complete and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluation on test set**"
      ],
      "metadata": {
        "id": "VTLO_FMaStKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "    print(\"Google Drive mounted successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"Error mounting Google Drive: {e}\")\n",
        "    raise\n",
        "\n",
        "print(\"Installing dependencies...\")\n",
        "!pip install transformers==4.38.2 evaluate datasets rouge_score --quiet\n",
        "\n",
        "# Loading fine-tuned model and tokenizer\n",
        "try:\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/SciFive_pubmedqa_Guestion_generation_finetuned\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/SciFive_pubmedqa_Guestion_generation_finetuned\")\n",
        "    model.to(\"cuda\")\n",
        "    model.eval()\n",
        "    print(\"Fine-tuned SciFive model and tokenizer loaded successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model/tokenizer: {e}\")\n",
        "    raise\n",
        "\n",
        "# Loading test dataset\n",
        "try:\n",
        "    with open('/content/test_data.json', 'r') as f:\n",
        "        test_data = json.load(f)\n",
        "    print(f\"Loaded test dataset with {len(test_data)} entries\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading test dataset: {e}\")\n",
        "    raise\n",
        "\n",
        "# Loading evaluation metrics\n",
        "try:\n",
        "    bleu = evaluate.load(\"bleu\")\n",
        "    rouge = evaluate.load(\"rouge\")\n",
        "    print(\"Evaluation metrics loaded successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading evaluation metrics: {e}\")\n",
        "    raise\n",
        "\n",
        "# Generating questions and evaluate\n",
        "results = []\n",
        "bleu_scores = []\n",
        "rouge_scores = []\n",
        "\n",
        "for item in tqdm(test_data, desc=\"Generating questions\"):\n",
        "    context = item.get(\"context\", \"\")\n",
        "    ground_truth_question = item.get(\"question\", \"\")\n",
        "\n",
        "    # Preparing input (As SciFive expects context as input for question generation)\n",
        "    input_text = context\n",
        "    try:\n",
        "        inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True).to(\"cuda\")\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=50,\n",
        "            num_beams=5,\n",
        "            do_sample=False,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "        generated_question = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
        "        if not generated_question.endswith(\"?\"):\n",
        "            generated_question += \"?\"\n",
        "\n",
        "        bleu_score = bleu.compute(predictions=[generated_question], references=[[ground_truth_question]])\n",
        "        rouge_score = rouge.compute(predictions=[generated_question], references=[ground_truth_question])\n",
        "\n",
        "        results.append({\n",
        "            \"context\": context,\n",
        "            \"ground_truth_question\": ground_truth_question,\n",
        "            \"generated_question\": generated_question,\n",
        "            \"bleu_score\": bleu_score[\"bleu\"],\n",
        "            \"rouge_score\": rouge_score\n",
        "        })\n",
        "        bleu_scores.append(bleu_score[\"bleu\"])\n",
        "        rouge_scores.append(rouge_score[\"rougeL\"])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating question for context: {context[:50]}...: {e}\")\n",
        "        results.append({\n",
        "            \"context\": context,\n",
        "            \"ground_truth_question\": ground_truth_question,\n",
        "            \"generated_question\": \"Error\",\n",
        "            \"bleu_score\": 0.0,\n",
        "            \"rouge_score\": {\"rougeL\": 0.0}\n",
        "        })\n",
        "        bleu_scores.append(0.0)\n",
        "        rouge_scores.append(0.0)\n",
        "\n",
        "avg_bleu = sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0.0\n",
        "avg_rougeL = sum(score for score in rouge_scores) / len(rouge_scores) if rouge_scores else 0.0\n",
        "\n",
        "output_file = \"/content/drive/MyDrive/test_results_scifive.json\"\n",
        "try:\n",
        "    with open(output_file, \"w\") as f:\n",
        "        json.dump({\n",
        "            \"results\": results,\n",
        "            \"average_bleu\": avg_bleu,\n",
        "            \"average_rougeL\": avg_rougeL\n",
        "        }, f, indent=4)\n",
        "    print(f\"Results saved to {output_file}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving results: {e}\")\n",
        "\n",
        "print(f\"Average BLEU Score: {avg_bleu:.4f}\")\n",
        "print(f\"Average ROUGE-L Score: {avg_rougeL:.4f}\")\n",
        "print(f\"Total questions generated: {len([r for r in results if r['generated_question'] != 'Error'])}/{len(test_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p3-m5VmMrjg",
        "outputId": "a70198d3-6f94-485b-efa4-92e8fd72103b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted successfully\n",
            "Installing dependencies...\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Fine-tuned SciFive model and tokenizer loaded successfully\n",
            "Loaded test dataset with 516 entries\n",
            "Evaluation metrics loaded successfully\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating questions: 100%|██████████| 516/516 [06:55<00:00,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to /content/drive/MyDrive/test_results_scifive.json\n",
            "Average BLEU Score: 0.1503\n",
            "Average ROUGE-L Score: 0.4175\n",
            "Total questions generated: 516/516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Average BLEU Score: 0.1503**\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "- A score of 0.1503 is relatively low, indicating that the generated questions have limited word-for-word overlap with the ground truth questions in test_data.json.\n",
        "\n",
        "- This suggests the model is generating questions that differ significantly in wording or structure from the expected questions, even if they might be semantically correct.\n",
        "\n",
        "- For example, if the ground truth is \"What pumps blood throughout the body?\" and the model generates \"What organ circulates blood?\", the BLEU score would be low due to different phrasing, despite similar meaning.\n",
        "\n",
        "- BLEU is sensitive to exact matches, so a low score doesn't necessarily mean the questions are incorrect, just differently worded.\n",
        "\n",
        "# **Average ROUGE-L Score: 0.4175**\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "- A score of 0.4175 is moderate, indicating that the generated questions share some structural and semantic similarity with the ground truth questions.\n",
        "\n",
        "- ROUGE-L is less strict than BLEU, focusing on shared sequences rather than exact n-grams, so the higher score suggests that the generated questions are capturing key concepts or phrases, even if the wording differs.\n",
        "\n",
        "- For example, \"What organ circulates blood?\" and \"What pumps blood throughout the body?\" share \"blood\" and a question structure, contributing to a decent ROUGE-L score.\n",
        "\n",
        "- The model is generating questions that are somewhat aligned with the ground truth in meaning or structure, which is positive."
      ],
      "metadata": {
        "id": "_ZFFAGceW284"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model_on_metrics(dataset, model, tokenizer, metric):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)  # Move model to the correct device\n",
        "\n",
        "    predictions = []\n",
        "    references = []\n",
        "\n",
        "    for example in dataset:\n",
        "        context = example['context']\n",
        "        question = example['question']\n",
        "\n",
        "        # Tokenize and move input tensors to the same device as the model\n",
        "        inputs = tokenizer(context, question, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "\n",
        "        # Generate the output\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(**inputs)\n",
        "\n",
        "        # Decode predictions\n",
        "        predicted_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        predictions.append(predicted_text)\n",
        "\n",
        "        # Wrap the reference in a list for BLEU\n",
        "        references.append([question])\n",
        "\n",
        "    # Compute the metric\n",
        "    metric.add_batch(predictions=predictions, references=references)\n",
        "    return metric.compute()\n"
      ],
      "metadata": {
        "id": "Bvy7j6S2RMLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = evaluate_model_on_metrics(dataset, model, tokenizer, metric)\n",
        "\n",
        "# Pretty print the output\n",
        "import pprint\n",
        "pprint.pprint(evaluation_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhzXlRClWU3G",
        "outputId": "bfaa0691-6f99-4f94-8d37-2c2a580aae8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bleu': 0.17576599789323155,\n",
            " 'brevity_penalty': 0.3515319957864631,\n",
            " 'length_ratio': 0.4888888888888889,\n",
            " 'precisions': [0.6818181818181818, 0.55, 0.4444444444444444, 0.375],\n",
            " 'reference_length': 45,\n",
            " 'translation_length': 22}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluating Using METEOR Score**"
      ],
      "metadata": {
        "id": "JzHW54HZLVQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "    print(\"Google Drive mounted successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"Error mounting Google Drive: {e}\")\n",
        "    raise\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/SciFive_pubmedqa_Guestion_generation_finetuned\"\n",
        "try:\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path, local_files_only=True)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
        "    model.to(\"cuda\")\n",
        "    model.eval()\n",
        "    print(\"Fine-tuned SciFive model and tokenizer loaded successfully from local path\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model or tokenizer: {e}\")\n",
        "    raise\n",
        "\n",
        "try:\n",
        "    with open('/content/test_data.json', 'r') as f:\n",
        "        test_data = json.load(f)\n",
        "    if not test_data:\n",
        "        raise ValueError(\"Test dataset is empty\")\n",
        "    print(f\"Loaded test dataset with {len(test_data)} entries\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading test dataset: {e}\")\n",
        "    raise\n",
        "\n",
        "# Loading METEOR metric\n",
        "try:\n",
        "    meteor = evaluate.load(\"meteor\")\n",
        "    print(\"METEOR metric loaded successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading METEOR metric: {e}\")\n",
        "    raise\n",
        "\n",
        "# Generating questions and evaluating with METEOR\n",
        "meteor_scores = []\n",
        "for item in tqdm(test_data, desc=\"Evaluating with METEOR\"):\n",
        "    context = item.get(\"context\", \"\")\n",
        "    ground_truth_question = item.get(\"question\", \"\")\n",
        "\n",
        "    if not context or not ground_truth_question:\n",
        "        print(f\"Skipping item due to missing context or question: {context[:50]}\")\n",
        "        meteor_scores.append(0.0)\n",
        "        continue\n",
        "\n",
        "    # Generating question\n",
        "    input_text = context\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True).to(\"cuda\")\n",
        "    try:\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=50,\n",
        "            num_beams=5,\n",
        "            do_sample=False,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "        generated_question = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
        "        if not generated_question.endswith(\"?\"):\n",
        "            generated_question += \"?\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating question for context {context[:50]}...: {e}\")\n",
        "        generated_question = \"Error\"\n",
        "        meteor_scores.append(0.0)\n",
        "        continue\n",
        "\n",
        "    # Computing METEOR score\n",
        "    try:\n",
        "        score = meteor.compute(predictions=[generated_question], references=[[ground_truth_question]])[\"meteor\"]\n",
        "        meteor_scores.append(score)\n",
        "    except Exception as e:\n",
        "        print(f\"Error computing METEOR score for {generated_question[:50]}...: {e}\")\n",
        "        meteor_scores.append(0.0)\n",
        "\n",
        "avg_meteor = sum(meteor_scores) / len(meteor_scores) if meteor_scores else 0.0\n",
        "avrage_meteor = avg_meteor\n",
        "print(f\"Average METEOR Score: {avrage_meteor:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0y_tv03LVkM",
        "outputId": "77e10aa7-87a3-4de2-a4ed-6e2696121ca3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted successfully\n",
            "Fine-tuned SciFive model and tokenizer loaded successfully from local path\n",
            "Loaded test dataset with 516 entries\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "METEOR metric loaded successfully\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating with METEOR: 100%|██████████| 516/516 [06:06<00:00,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average METEOR Score: 0.9054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluation Results for Fine-Tuned SciFive Model**\n",
        "\n",
        "# Model Performance Metrics\n",
        "- **Dataset Size**: 5,158 entries, split into 80% train (4,126), 10% eval (516), and 10% test (516).\n",
        "- **Evaluation Metrics**:\n",
        "  - **BLEU Score**: 0.1503\n",
        "    - Indicates limited word-for-word overlap with ground truth questions, likely due to varied phrasing despite semantic correctness.\n",
        "  - **ROUGE-L Score**: 0.4175\n",
        "    - Suggests moderate structural and semantic similarity, effectively capturing key concepts.\n",
        "  - **METEOR Score**: 0.9054\n",
        "    - Reflects high semantic alignment and synonymy, complementing BLEU and ROUGE-L by accounting for paraphrased yet meaningful questions.\n",
        "- **Total Questions Generated**: 516/516 (100% success rate with no errors).\n",
        "- **Inference Time**: Approximately 6 minutes 55 seconds for BLEU/ROUGE-L evaluation, and 6 minutes 6 seconds for METEOR evaluation, averaging 1.24–1.41 questions per second.\n",
        "- **Confidence Scores**: Range from 0.955 to 0.987 across test cases, indicating strong model certainty.\n",
        "\n",
        "### Observations\n",
        "- The high METEOR score (0.9054) suggests the model generates semantically accurate questions, addressing the limitation of BLEU's focus on exact matches.\n",
        "- The stable generation of all 516 test questions with high confidence underscores the model's robustness on the given dataset."
      ],
      "metadata": {
        "id": "0ORJZPXGSNk4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Saving the model to the drive**"
      ],
      "metadata": {
        "id": "PWTSvgRtHcCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model and tokenizer locally\n",
        "model.save_pretrained(\"/content/SciFive_pubmedqa_Guestion_generation_finetuned\")\n",
        "tokenizer.save_pretrained(\"/content/SciFive_pubmedqa_Guestion_generation_finetuned\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp -r /content/SciFive_pubmedqa_Guestion_generation_finetuned /content/drive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqpxK7gmHe8T",
        "outputId": "ce5f6254-3cd9-44e0-dd88-a1e1c1bf7a41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Saving as onnox**"
      ],
      "metadata": {
        "id": "kcA4f-_nItJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set paths\n",
        "model_path = \"./SciFive_pubmedqa_Guestion_generation_finetuned\"\n",
        "output_path = Path(\"QG_pubmedaq_onnx_output/\")\n",
        "\n",
        "main_export(\n",
        "    model_name_or_path=model_path,\n",
        "    output=output_path,\n",
        "    task=\"text2text-generation\",\n",
        "    opset=14  # This is the minimum required for T5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ax9AhBOIsza",
        "outputId": "acc511b1-ce01-4209-d34f-cd14e4863047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/t5/modeling_t5.py:1318: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if sequence_length != 1:\n",
            "Could not find ONNX initializer for torch parameter decoder.embed_tokens.weight. decoder.embed_tokens.weight will not be checked for deduplication.\n",
            "Could not find ONNX initializer for torch parameter encoder.embed_tokens.weight. encoder.embed_tokens.weight will not be checked for deduplication.\n",
            "Found different candidate ONNX initializers (likely duplicate) for the tied weights:\n",
            "\tdecoder.embed_tokens.weight: set() --> ignored (may be a parameter from a part of the model not exported)\n",
            "\tencoder.embed_tokens.weight: set() --> ignored (may be a parameter from a part of the model not exported)\n",
            "\tlm_head.weight: {'onnx::MatMul_2881'}\n",
            "\tshared.weight: {'shared.weight'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading the model from drive**"
      ],
      "metadata": {
        "id": "XBprh5caHr-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/SciFive_pubmedqa_Guestion_generation_finetuned\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/SciFive_pubmedqa_Guestion_generation_finetuned\")"
      ],
      "metadata": {
        "id": "Xo8ywSmqHsPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference with the Fine-Tuned Model**"
      ],
      "metadata": {
        "id": "ZakaGWBn3oFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_question(model, tokenizer, context, max_length=100):\n",
        "    # Tokenizing the context\n",
        "    inputs = tokenizer(context, return_tensors=\"pt\", padding='max_length', truncation=True, max_length=512)\n",
        "\n",
        "    # Generating the question\n",
        "    output = model.generate(\n",
        "        inputs['input_ids'],\n",
        "        max_length=max_length,\n",
        "        num_beams=4,\n",
        "        no_repeat_ngram_size=2,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    # Decoding and returning the generated question\n",
        "    question = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return question\n",
        "\n",
        "# Test inference on the dataset\n",
        "for item in test_data[:5]:  # Example with the first 5 items in the test dataset\n",
        "    context = item[\"context\"]\n",
        "    print(\"Context:\", context)\n",
        "    generated_question = generate_question(model, tokenizer, context)\n",
        "    print(\"Generated Question:\", generated_question)\n",
        "    print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Usi46psw3otx",
        "outputId": "0ef049c8-f417-49cd-aed8-2d459569c85c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context: Symmetric encryption uses the same key for both encryption and decryption, while asymmetric encryption uses a pair of keys: a public key for encryption and a private key for decryption.\n",
            "Generated Question: What is the difference between symmetric and asymmetric encryption?\n",
            "--------------------------------------------------------------------------------\n",
            "Context: Non-maximum suppression is used to thin the edges by suppressing pixels that are not local maxima in the gradient direction, ensuring that only the most prominent edges are retained.\n",
            "Generated Question: True or False: Non-maximum suppression thins edges by suppressing pixels that are not local maxima.\n",
            "--------------------------------------------------------------------------------\n",
            "Context: The average of token vectors may lose important syntactic and semantic information, leading to less effective sentence embeddings.\n",
            "Generated Question: True or False: The average of token vectors may lose important syntactic and semantic information.\n",
            "--------------------------------------------------------------------------------\n",
            "Context: The primary motivation is to address the issue of translating long sentences by allowing the model to focus on the most relevant parts of the input, instead of encoding the entire sentence into a fixed-size vector.\n",
            "Generated Question: Fill in the blank: The primary motivation is to address the issue of translating long sentences.\n",
            "--------------------------------------------------------------------------------\n",
            "Context: A virtualization attack exploits vulnerabilities in the virtualization platform to compromise the confidentiality, integrity, or availability of shared cloud resources.\n",
            "Generated Question: True or False: A virtualization attack compromises confidentiality, integrity, or resource availability.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_advanced_question(model, tokenizer, context, max_length=100, question_type=\"auto\"):\n",
        "\n",
        "    inputs = tokenizer(context, return_tensors=\"pt\", padding='max_length', truncation=True, max_length=512)\n",
        "\n",
        "    logits_processor = LogitsProcessorList([\n",
        "        MinLengthLogitsProcessor(10, eos_token_id=tokenizer.eos_token_id)\n",
        "    ])\n",
        "\n",
        "    output = model.generate(\n",
        "        inputs['input_ids'],\n",
        "        attention_mask=inputs['attention_mask'],\n",
        "        max_length=max_length,\n",
        "        num_beams=5,\n",
        "        num_return_sequences=1,\n",
        "        no_repeat_ngram_size=2,\n",
        "        early_stopping=True,\n",
        "        return_dict_in_generate=True,\n",
        "        output_scores=True,\n",
        "        logits_processor=logits_processor\n",
        "    )\n",
        "\n",
        "    question = tokenizer.decode(output.sequences[0], skip_special_tokens=True)\n",
        "\n",
        "    # Calculating confidence (mean log prob of predicted tokens)\n",
        "    scores = output.scores\n",
        "    if scores:\n",
        "        probs = [torch.nn.functional.softmax(score, dim=-1).max().item() for score in scores]\n",
        "        avg_confidence = sum(probs) / len(probs)\n",
        "    else:\n",
        "        avg_confidence = None\n",
        "\n",
        "    return {\n",
        "        \"context\": context,\n",
        "        \"question\": question,\n",
        "        \"confidence_score\": round(avg_confidence, 3) if avg_confidence else \"N/A\",\n",
        "        \"question_type\": question_type\n",
        "    }\n",
        "\n",
        "# Testing on more samples\n",
        "results = []\n",
        "for i, item in enumerate(test_data[:10]):  # Test on first 10\n",
        "    context = item[\"context\"]\n",
        "    result = generate_advanced_question(model, tokenizer, context)\n",
        "    print(f\"Sample {i+1}\")\n",
        "    print(\"Context:\", context)\n",
        "    print(\"Generated Question:\", result[\"question\"])\n",
        "    print(\"Confidence Score:\", result[\"confidence_score\"])\n",
        "    print(\"-\" * 100)\n",
        "    results.append(result)\n",
        "\n",
        "with open(\"advanced_generated_questions.json\", \"w\") as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n",
        "print(\"Saved results to 'advanced_generated_questions.json'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqiwAKDiIKE9",
        "outputId": "16cf4b16-0614-4c56-ad5c-e3159dcc583b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1\n",
            "Context: Symmetric encryption uses the same key for both encryption and decryption, while asymmetric encryption uses a pair of keys: a public key for encryption and a private key for decryption.\n",
            "Generated Question: What is the difference between symmetric and asymmetric encryption?\n",
            "Confidence Score: 0.985\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Sample 2\n",
            "Context: Non-maximum suppression is used to thin the edges by suppressing pixels that are not local maxima in the gradient direction, ensuring that only the most prominent edges are retained.\n",
            "Generated Question: True or False: Non-maximum suppression thins edges by suppressing pixels that are not local maxima.\n",
            "Confidence Score: 0.971\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Sample 3\n",
            "Context: The average of token vectors may lose important syntactic and semantic information, leading to less effective sentence embeddings.\n",
            "Generated Question: True or False: The average of token vectors may lose important syntactic and semantic information.\n",
            "Confidence Score: 0.982\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Sample 4\n",
            "Context: The primary motivation is to address the issue of translating long sentences by allowing the model to focus on the most relevant parts of the input, instead of encoding the entire sentence into a fixed-size vector.\n",
            "Generated Question: Fill in the blank: The primary motivation is to address the issue of translating long sentences.\n",
            "Confidence Score: 0.963\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Sample 5\n",
            "Context: A virtualization attack exploits vulnerabilities in the virtualization platform to compromise the confidentiality, integrity, or availability of shared cloud resources.\n",
            "Generated Question: True or False: A virtualization attack compromises confidentiality, integrity, or resource availability.\n",
            "Confidence Score: 0.983\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Sample 6\n",
            "Context: The main purpose of distributed systems is to overcome the constraints of a single machine, such as limited processing power and storage capacity.\n",
            "Generated Question: What is the main purpose of distributed systems?\n",
            "Confidence Score: 0.975\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Sample 7\n",
            "Context: Opportunity cost is the value of the next best alternative that is forgone when a decision is made. It represents the potential profit lost from not choosing the next best option.\n",
            "Generated Question: What is the opportunity cost in decision making?\n",
            "Confidence Score: 0.966\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Sample 8\n",
            "Context: Node classification predicts the label of a node based on its embedding, while link prediction predicts the existence of an edge between two nodes based on their embeddings.\n",
            "Generated Question: What is the difference between node classification and link prediction?\n",
            "Confidence Score: 0.978\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Sample 9\n",
            "Context: One-vs-all classification decomposes a multiclass problem into multiple binary classification tasks, where each classifier is trained to predict whether an instance belongs to a specific class or not.\n",
            "Generated Question: True or False: One-vs-all classification decomposes multiclass problems into binary classification tasks.\n",
            "Confidence Score: 0.964\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Sample 10\n",
            "Context: Soft prompt tuning modifies only the input layer by appending trainable tokens, while prefix tuning prepends trainable tensors at each transformer block, allowing more control and stability during training.\n",
            "Generated Question: True or False: Soft prompt tuning modifies only the input layer, while prefix tuning prepends trainable tensors.\n",
            "Confidence Score: 0.968\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Saved results to 'advanced_generated_questions.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generate Exam Questions Using the QG Model for the Analasis Of algorithms Module**"
      ],
      "metadata": {
        "id": "xoyIXKOcbAAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/SciFive_pubmedqa_Guestion_generation_finetuned\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/SciFive_pubmedqa_Guestion_generation_finetuned\")\n",
        "\n",
        "def generate_advanced_question(model, tokenizer, context, max_length=100, question_type=\"auto\"):\n",
        "    inputs = tokenizer(context, return_tensors=\"pt\", padding='max_length', truncation=True, max_length=512)\n",
        "\n",
        "    logits_processor = LogitsProcessorList([\n",
        "        MinLengthLogitsProcessor(10, eos_token_id=tokenizer.eos_token_id)\n",
        "    ])\n",
        "\n",
        "    output = model.generate(\n",
        "        inputs['input_ids'],\n",
        "        attention_mask=inputs['attention_mask'],\n",
        "        max_length=max_length,\n",
        "        num_beams=5,\n",
        "        num_return_sequences=1,\n",
        "        no_repeat_ngram_size=2,\n",
        "        early_stopping=True,\n",
        "        return_dict_in_generate=True,\n",
        "        output_scores=True,\n",
        "        logits_processor=logits_processor\n",
        "    )\n",
        "\n",
        "    question = tokenizer.decode(output.sequences[0], skip_special_tokens=True)\n",
        "\n",
        "    scores = output.scores\n",
        "    if scores:\n",
        "        probs = [torch.nn.functional.softmax(score, dim=-1).max().item() for score in scores]\n",
        "        avg_confidence = sum(probs) / len(probs)\n",
        "    else:\n",
        "        avg_confidence = None\n",
        "\n",
        "    return {\n",
        "        \"context\": context,\n",
        "        \"question\": question,\n",
        "        \"confidence_score\": round(avg_confidence, 3) if avg_confidence else \"N/A\",\n",
        "        \"question_type\": question_type,\n",
        "        \"question_id\": str(uuid4())\n",
        "    }\n",
        "\n",
        "# Module-specific contexts\n",
        "contexts = [\n",
        "    {\n",
        "        \"context\": \"Asymptotic notations such as Big O, Big Theta, and Big Omega are used to analyze the performance of algorithms by describing their running time or space requirements as the input size grows.\"\n",
        "    },\n",
        "    {\n",
        "        \"context\": \"Recursive algorithms, such as the factorial function, can be analyzed by deriving recurrence relations and solving them using methods like Backward Substitution.\"\n",
        "    },\n",
        "    {\n",
        "        \"context\": \"The Greedy paradigm involves making locally optimal choices at each step to find a global optimum, as exemplified by Kruskal’s Algorithm for finding minimum spanning trees.\"\n",
        "    },\n",
        "    {\n",
        "        \"context\": \"Divide-and-Conquer algorithms, like Merge Sort, break a problem into smaller sub-problems, solve them recursively, and combine the solutions efficiently.\"\n",
        "    },\n",
        "    {\n",
        "        \"context\": \"Dynamic Programming improves the efficiency of algorithms by storing the results of sub-problems to avoid redundant computations, as seen in the Fibonacci sequence calculation.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "results = []\n",
        "for i, item in enumerate(contexts[:5]):  # Generate 5 questions\n",
        "    context = item[\"context\"]\n",
        "    result = generate_advanced_question(model, tokenizer, context, max_length=150)\n",
        "    print(f\"Sample {i+1}\")\n",
        "    print(\"Context:\", context)\n",
        "    print(\"Generated Question:\", result[\"question\"])\n",
        "    print(\"Confidence Score:\", result[\"confidence_score\"])\n",
        "    print(\"Question ID:\", result[\"question_id\"])\n",
        "    print(\"-\" * 100)\n",
        "    results.append(result)\n",
        "\n",
        "with open(\"advanced_generated_questions.json\", \"w\") as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n",
        "print(\"Saved results to 'advanced_generated_questions.json'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9ENnhK2Z-Wx",
        "outputId": "3ece3d99-a44e-4db6-8784-110146e4d56a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1\n",
            "Context: Asymptotic notations such as Big O, Big Theta, and Big Omega are used to analyze the performance of algorithms by describing their running time or space requirements as the input size grows.\n",
            "Generated Question: What is the purpose of asymptotic notations such as Big O, Big Theta, and Big Omega?\n",
            "Confidence Score: 0.984\n",
            "Question ID: 42a2a83e-24b6-4be9-99e9-952e1b4b9fe8\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Sample 2\n",
            "Context: Recursive algorithms, such as the factorial function, can be analyzed by deriving recurrence relations and solving them using methods like Backward Substitution.\n",
            "Generated Question: True or False: Recursive algorithms can be analyzed using recurrence relations.\n",
            "Confidence Score: 0.969\n",
            "Question ID: 5414f485-2331-4b33-86b9-5e544fa4ede1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Sample 3\n",
            "Context: The Greedy paradigm involves making locally optimal choices at each step to find a global optimum, as exemplified by Kruskal’s Algorithm for finding minimum spanning trees.\n",
            "Generated Question: What is the purpose of the Greedy paradigm?\n",
            "Confidence Score: 0.966\n",
            "Question ID: 77b83003-0424-4fe0-b71b-a652724ad7d1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Sample 4\n",
            "Context: Divide-and-Conquer algorithms, like Merge Sort, break a problem into smaller sub-problems, solve them recursively, and combine the solutions efficiently.\n",
            "Generated Question: What are Divide-and-Conquer algorithms, like Merge Sort?\n",
            "Confidence Score: 0.987\n",
            "Question ID: 90e8305c-aec4-4aa1-9ba0-55d4b3dbefe4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Sample 5\n",
            "Context: Dynamic Programming improves the efficiency of algorithms by storing the results of sub-problems to avoid redundant computations, as seen in the Fibonacci sequence calculation.\n",
            "Generated Question: How does Dynamic Programming improve algorithms?\n",
            "Confidence Score: 0.955\n",
            "Question ID: 7cf7c013-81c0-4347-956e-6e01322ee1bf\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Saved results to 'advanced_generated_questions.json'\n"
          ]
        }
      ]
    }
  ]
}